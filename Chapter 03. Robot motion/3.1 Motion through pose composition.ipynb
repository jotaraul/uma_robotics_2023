{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Motion through pose composition\n",
    "\n",
    "A fundamental aspect of the development of mobile robots is the motion itself. In an idyllic world, motion commands are sent to the robot locomotion system, which perfectly executes them and drives the robot to a desired location. However, this is not a trivial matter, as many sources of motion error appear: \n",
    "- wheel slippage, \n",
    "- inaccurate calibration,\n",
    "- limited resolution during integration (time increments, measurement resolution), or\n",
    "- unequal floor, among others.\n",
    "\n",
    "These factors introduce uncertainty in the robot motion. Additionally, other constraints to the movement difficult its implementation. This particular chapter explores the concept of *robot's pose* and how we deal with it in a probabilistic context.\n",
    "\n",
    "The pose itself can take multiple forms depending on the problem context:\n",
    "\n",
    "- **2D location**: In a planar context we only need to a 2d vector $[x, y]^T$ to locate a robot against a point of reference, the origin $(0, 0).$\n",
    "- **2D pose**: In most cases involving mobile robots, the location alone is insufficient. We need an additional parameter known as orientation or *bearing*. Therefore, a robot's pose is usually expressed as $[x, y, \\theta]^T$ (see Fig. 1). *In the rest of the book, we mostly refer to this one.*\n",
    "- **3D pose**: Although we will only mention it in passing, for robotics applications in the 3D space, *i.e.* UAV or drones, not only a third axis $z$ is added, but to handle the orientation in a 3D environment we need 3 components, *i.e.* roll, pitch and yaw. This course is centered around planar mobile robots so we will not use this one, nevertheless most methods could be adapted to 3D environments.\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/pose-composition.png\" alt=\"\" width=\"400px\">\n",
    "  <figcaption>Fig. 1: Example of an initial 2D robot pose ($p_1$) and its resultant pose ($p_2$) after completing a motion ($\\Delta p$).</figcaption>\n",
    "</figure>\n",
    "\n",
    "In this chapter we will explore how to use the **composition of poses** to express poses in a certain reference system, while the next two chapters describe two probabilistic methods for dealing with the uncertainty inherent to robot motion, namely the **velocity-based** motion model and the **odometry-based** one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.tcomp import tcomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">OPTIONAL</span>\n",
    "\n",
    "<span style=\"color:green\">In the Robot motion lecture, we started talking about *Differential drive* motion systems. Include as many cells as needed to introduce the background that you find interesting about it and some code illustrating some related aspect, for example, a code computing and plotting the *Instantaneus Center of Rotation (ICR)* according to a number of given parameters.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">***END OF OPTIONAL PART***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pose composition <a id=\"pose_composition\"></a>\n",
    "\n",
    "The composition of posses is a tool that permits us to express the *final* pose of a robot in an arbitrary coordinate system. Given an initial pose $p_1$ and a pose differential $\\Delta p$ (pose increment), *i.e.* how much the robot has moved during an interval of time, the final pose $p$ can be computed using the **composition of poses** function:\n",
    "\n",
    "$$\n",
    "    p_1 = \n",
    "        \\begin{bmatrix}\n",
    "            x_1 \\\\ y_1 \\\\ \\theta_1\n",
    "        \\end{bmatrix}, \\, \\, \\,\n",
    "    \\Delta p = \n",
    "        \\begin{bmatrix}\n",
    "            \\Delta x \\\\ \\Delta y \\\\ \\Delta \\theta\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\begin{equation}\n",
    "    p = \\begin{bmatrix}\n",
    "            x \\\\ y \\\\ \\theta\n",
    "        \\end{bmatrix}\n",
    "        = p_1 \\oplus \\Delta p\n",
    "        = \\begin{bmatrix}\n",
    "            x_1 + \\Delta x \\cos \\theta_1 - \\Delta y \\sin \\theta_1 \\\\ \n",
    "            y_1 + \\Delta x \\sin \\theta_1 + \\Delta y \\cos \\theta_1 \\\\\n",
    "            \\theta_1 + \\Delta \\theta\n",
    "          \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "The differential $\\Delta p$, although we are using it as control in this exercise, normally is calculated given the robot's locomotion or sensed by the wheel encoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">OPTIONAL</span>\n",
    "\n",
    "<span style=\"color:green\">Implement your own methods to compute the composition of two poses, as well as the inverse composition. Include some examples of their utilization, also incorporating plots.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">***END OF OPTIONAL PART***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Moving the robot by composing pose increments</i></b></span>**\n",
    "\n",
    "Take a look at the `Robot()` class provided and its methods: the constructor, `step()` and `draw()`. Then, modify the main function in the next cell for the robot to describe a $8m \\times 8m$ square path as seen in the figure below. You must take into account that:\n",
    "\n",
    "- The robot starts in the bottom-left corner $(0, 0)$ heading north and \n",
    "- moves at increments of $2 m$ each step. \n",
    "- Each 4 steps, it will turn right.\n",
    "\n",
    "**Example**\n",
    "\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-1-1.png\" alt=\"\">\n",
    "  <figcaption>Fig. 2: Route of our robot.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot():\n",
    "    '''Mobile robot implementation\n",
    "    \n",
    "        Attr:\n",
    "            pose: Expected position of the robot\n",
    "    '''\n",
    "    def __init__(self, mean):\n",
    "        self.pose = mean\n",
    "\n",
    "    def step(self, u):\n",
    "        self.pose = tcomp(self.pose, u)\n",
    "    \n",
    "    def draw(self, fig, ax):\n",
    "        DrawRobot(fig, ax, self.pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(robot):\n",
    "    \n",
    "    # PARAMETERS INITIALIZATION\n",
    "    num_steps = 15 # Number of robot motions\n",
    "    turning = 4  # Number of steps for turning\n",
    "    u = np.vstack([2., 0., 0.]) # Motion command (pose increment)\n",
    "    angle_inc = -np.pi/2 # Angle increment\n",
    "    \n",
    "    # VISUALIZATION\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()\n",
    "    plt.draw()\n",
    "    plt.xlim((-2, 10))\n",
    "    plt.ylim((-2, 10))\n",
    "    plt.fill([2, 2, 6, 6],[2, 6, 6, 2],facecolor='lightgray', edgecolor='gray', linewidth=3)\n",
    "    \n",
    "    plt.grid()\n",
    "    robot.draw(fig, ax)\n",
    "    \n",
    "    # MAIN LOOP\n",
    "    for step in range(1,num_steps+1):\n",
    "        \n",
    "        # Check if the robot has to move in straight line or also has to turn\n",
    "        # and accordingly set the third component (rotation) of the motion command \n",
    "        if not None:\n",
    "            u[2] = None \n",
    "        else:\n",
    "            u[2] = None\n",
    "             \n",
    "        # Execute the motion command        \n",
    "        robot.step(u)\n",
    "        \n",
    "        # VISUALIZATION        \n",
    "        robot.draw(fig, ax)        \n",
    "        clear_output(wait=True)\n",
    "        display(fig)        \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following code cell to **try your code**. The resulting figure must be the same as Fig. 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN \n",
    "initial_pose = np.vstack([0., 0., np.pi/2])\n",
    "robot = Robot(initial_pose)\n",
    "main(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Considering noise\n",
    "\n",
    "In the previous case, the robot motion was error-free. This is overly optimistic as in a real use case the conditions of the environment are a huge source of uncertainty.\n",
    "\n",
    "To take into consideration such uncertainty, we will model the movement of the robot as a (multidimensional) gaussian distribution $\\Delta p \\sim N(\\mu_{\\Delta p},\\Sigma_{\\Delta p})$ where:\n",
    "\n",
    "- The mean $\\mu_{\\Delta p}$ is still the pose differential in the previous exercise, that is $\\Delta p_{\\text{given}}$.\n",
    "- The covariance $\\Sigma_{\\Delta p}$ is a $3 \\times 3$ matrix, which defines the amount of error at each step (time interval). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Adding noise to the pose motion</i></b></span>**\n",
    "\n",
    "Now, we are going to add a Gaussian noise to the motion, assuming that the incremental motion now follows the probability distribution:\n",
    "\n",
    "$$\n",
    "    \\Delta p = N(\\Delta p_{given}, \\Sigma_{\\Delta p})\n",
    "    \\textit{ with } \n",
    "    \\Sigma_{\\Delta p}  =\n",
    "        \\begin{bmatrix}\n",
    "            0.04 & 0 & 0 \\\\\n",
    "            0 & 0.04 & 0 \\\\\n",
    "            0 & 0 & 0.01\n",
    "        \\end{bmatrix}\n",
    "    (\\text{ units in }m^2 \\text{ and } rad^2)\n",
    "$$\n",
    "\n",
    "For doing that, complete the `NosyRobot()` class below, which is a child class of the previous `Robot()` one. Concretely, you have to:\n",
    "\n",
    "- Complete this new class by adding some amount of noise to the movement (take a look at the `step()` method. *Hints: [`np.vstack()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html), [`stats.multivariate_normal.rvs()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html)*. \n",
    "Remark that we have now two variables related to the robot pose:\n",
    "  - `self.pose`, which represents the expected, *ideal* pose, and\n",
    "  - `self.true_pose`, that stands for the actual pose after carrying out a noisy motion command.\n",
    "- Along with the expected pose drawn in red (`self.pose`), in the `draw()` method plot the real pose of the robot (`self.true_pose`) in blue, which as commented is affected by noise. \n",
    "\n",
    "Run the cell several times to see that the motion (and the path) is different each time. Try also with different values of the covariance matrix.\n",
    "\n",
    "**Example**\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-1-2.png\" alt=\"\">\n",
    "  <figcaption>Fig. 3: Movement of our robot using pose compositions. <br/>\n",
    "      Containing the expected poses (in red) and the true pose <br/> affected by noise (in blue)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyRobot(Robot):\n",
    "    \"\"\"Mobile robot implementation. It's motion has a set ammount of noise.\n",
    "    \n",
    "        Attr:\n",
    "            pose: Inherited from Robot\n",
    "            true_pose: Real robot pose, which has been affected by some ammount of noise.\n",
    "            covariance: Amount of error of each step.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, covariance):\n",
    "        super().__init__(mean)\n",
    "        self.true_pose = mean\n",
    "        self.covariance = covariance\n",
    "        \n",
    "    def step(self, step_increment):\n",
    "        \"\"\"Computes a single step of our noisy robot.\n",
    "        \n",
    "            super().step(...) updates the expected pose (without noise)\n",
    "            Generate a noisy increment based on step_increment and self.covariance.\n",
    "            Then this noisy increment is applied to self.true_pose\n",
    "        \"\"\"\n",
    "        super().step(step_increment)\n",
    "        true_step = None\n",
    "        self.true_pose = tcomp(None, None)\n",
    "        \n",
    "    def draw(self, fig, ax):\n",
    "        super().draw(fig, ax)\n",
    "        DrawRobot(fig, ax, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN \n",
    "initial_pose = np.vstack([0., 0., np.pi/2])\n",
    "cov = np.diag([0.04, 0.04, 0.01])  \n",
    "\n",
    "robot = NoisyRobot(initial_pose, cov)\n",
    "main(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Now that you are an expert in retrieving the pose of a robot after carrying out a motion command defined as a pose increment, **answer the following questions**:\n",
    "\n",
    "- Why are the expected (red) and true (blue) poses different?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- In which scenario could they be the same?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- How affect the values in the covariance matrix $\\Sigma_{\\Delta p}$ the robot motion?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
