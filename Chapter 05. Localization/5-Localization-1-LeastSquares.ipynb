{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Least Squares Global Localization\n",
    "\n",
    "Least Squares Positioning is a well-known algorithm for estimating the robot localization $x$ given a set of known landmarks in a map. Least Squares is akin to find the best pose $\\hat{x}$ by solving a system of equations of the form:\n",
    "\n",
    "$$z_{m \\times 1} = H_{m \\times n} \\cdot x_{n \\times 1}$$\n",
    "\n",
    "where: \n",
    "- $n$ is the length of the pose ($n=3$ in our case, position plus orientation),\n",
    "- $m$ represents the number of observations, and \n",
    "- $H$ is the matrix that codifies the observation model relating the measurement $z$ with the robot pose $x$. \n",
    "\n",
    "This simple concept, nevertheless, has to be modified in order to be used  in real scenarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 Pseudo-inverse\n",
    "\n",
    "Generally, to solve an equation system, we only need as many equations as variables. In the robot localization problem, each observation $z$ sets an equation, while the variables are the components of the state/pose, $x$. \n",
    "\n",
    "In such a case, where $n=m$, a direct attempt to this problem exists:\n",
    "\n",
    "  $$x = H ^{-1} z$$\n",
    "\n",
    "So a unique solution exists if $H$ is invertible, that is, $H$ is a square matrix with $det(H) \\neq 0$. \n",
    "\n",
    "However, in real scenarios typically there are available more observations than variables. An approach to address this could be to drop some of the additional equations, but given that observations $z$ are inaccurate (they have been affected by some noise), we may use the additional information to try to mitigate such noise. However, by doing that $H$ is no a squared matrix anymore, hence not being invertible. \n",
    "\n",
    "Two tools can help us at this point. The first one is the utilization of **Least Squares** to find the closest possible $\\hat{x}$, i.e. the one where the the error ($e = Hx -z$) is minimal:\n",
    "\n",
    "  $$ \\hat x = \\arg\\min_{x} e^Te = [(z-Hx)^T(z-Hx)] = \\arg\\min_x || z-Hx ||^2$$\n",
    "\n",
    "which has a close form solution using the **pseudo-inverse** of a matrix:\n",
    "  \n",
    "  $$\\hat{x} = \\underbrace{(H^T H)^{-1} H^T}_{\\textit{pseudo-inverse }(H^+)} z$$\n",
    "\n",
    "The **pseudo-inverse**, in contrast to the normal inverse operation, can be used in non-square matrices!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "#%matplotlib inline\n",
    "\n",
    "# IMPORTS\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.PlotEllipse import PlotEllipse\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.tcomp import tcomp\n",
    "from utils.tinv import tinv, jac_tinv1 as jac_tinv\n",
    "from utils.Jacobians import J1, J2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Playing with a robot in a corridor</i></b></span>** \n",
    "\n",
    "The following code illustrates a simple scenario where a robot is in a corridor looking at a door, which is placed at the origin of the reference system (see Fig.1). The robot is equipped with a laser scanner able to measure distances, and takes a number of observations $z$. The robot is placed 3 meters away from the door, but this information is unknown for it. **Your goal is** to estimate the position of the robot in this 1D world using such measurements. $\\\\[5pt]$\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/corridor.png\" alt=\"\">\n",
    "  <figcaption>Fig. 1: Simple 1D scenario with a robot equipped with a laser scanner measuring distance to a door.</figcaption>\n",
    "</figure>\n",
    "\n",
    "The following code cell shows the dimensions of all the actors involved in LS-positioning. Complete it for computing the robot pose $x$ from the available information. *Recall [`np.linalg.inv()`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the robot pose to unknown\n",
    "x = np.vstack(np.array([None]))\n",
    "\n",
    "# Sensor measurements to the door\n",
    "z = np.vstack(np.array([3.7,2.9,3.6,2.5,3.5]))\n",
    "\n",
    "# Observation model\n",
    "H = np.ones(np.array([5,1]))\n",
    "\n",
    "print (\"Dimensions:\")\n",
    "print (\"Pose x:         \" + str(x.shape))\n",
    "print (\"Observations z: \" + str(z.shape))\n",
    "print (\"Obs. model H:   \" + str(H.shape))\n",
    "print (\"H.T@H:          \" + str((H.T@H).shape))\n",
    "print (\"inv(H.T@H):     \" + str((np.linalg.inv(H.T@H)).shape))\n",
    "print (\"H.T@z :         \" + str((H.T@z).shape))\n",
    "\n",
    "# Do Least Squares Positioning\n",
    "x = None\n",
    "\n",
    "print('\\nLS-Positioning')\n",
    "print('x = ' + str(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output</span>\n",
    "\n",
    "```\n",
    "x = [3.24]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.2 Weighted measurements\n",
    "\n",
    "In cases where multiple sensors affected by different noise profiles are used, or in those where the robot is using a sensor with a varying error (*e.g.* typically radial laser scans are more accurate while measuring distances to close objects), it is interesting to weight the contribution of such measurements while retrieving the robot pose. For example, we are going to consider a sensor whose accuracy drops the further the observed landmark is. Given a *covariance* matrix $Q$ describing the error in the measurements, the equations above are rewritten as:\n",
    "\n",
    "  $$ \\hat x = \\arg\\min_{x} e^T Q^{-1} e = [(Hx-z)^TQ^{-1}(Hx-z)] $$\n",
    "\n",
    "  $$\n",
    "    \\begin{aligned}\n",
    "      &\\hat{x} \\leftarrow (H^T Q^{-1} H)^{-1} H^T Q^{-1} z &\\text{(1. Best estimation)}\\\\ \n",
    "      &\\Sigma_{\\hat{x}} \\leftarrow (H^T Q^{-1} H)^{-1} &\\text{(2. Uncertainty of the estimation)}\\\\\n",
    "    \\end{aligned}\n",
    "  $$\n",
    "  \n",
    "  Example with three measurements having different uncertainty ($\\sigma_1^2$, $\\sigma_2^2$, $\\sigma_3^2$):\n",
    "  \n",
    "  $$\n",
    "  e^T Q^{-1} e = [e_1 \\; e_2 \\; e_3]\n",
    "  \\begin{bmatrix} 1 / \\sigma_1^2 & 0 & 0 \\\\ 0 & 1/\\sigma_2^2 & 0 \\\\ 0 & 0 & 1/\\sigma_3^2 \\end{bmatrix} \n",
    "  \\begin{bmatrix} e_1 \\\\ e_2 \\\\ e_3 \\end{bmatrix}\n",
    "  = \\frac{e_1^2}{\\sigma_1^2} + \\frac{e_2^2}{\\sigma_2^2} + \\frac{e_3^2}{\\sigma_3^2}\n",
    "  = \\sum_{i=1}^m \\frac{e_i^2}{\\sigma_i^2}\n",
    "  $$\n",
    "  \n",
    "  In this way, the bigger the $\\sigma_i^2$, the smaller its contribution to the pose's computation.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Adding growing uncertainty</i></b></span>** \n",
    "\n",
    "We have new information! The manufacturer of the laser scanner mounted on the robot wrote an email telling us that the device is considerably more inaccurate for further distances. Concretely, such uncertainty is characterized by $\\sigma^2=e^z$ (the laser is not so accurate, being polite).\n",
    "\n",
    "With this new information, implement the computation of the weighted LS-positioning so you can compare the previously estimated position with the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sensor measurements to the door\n",
    "z = np.vstack(np.array([3.7,2.9,3.6,2.5,3.5]))\n",
    "\n",
    "# Uncertainty of the measurements\n",
    "Q = np.eye(5)*np.exp(z)\n",
    "\n",
    "# Observation model\n",
    "H = np.ones(np.array([5,1]))\n",
    "\n",
    "# Do Least Squares Positioning\n",
    "x = None\n",
    "\n",
    "# Do Weighted Least Squares Positioning\n",
    "x_w = None\n",
    "\n",
    "print('\\nLS-Positioning')\n",
    "print('x = ' + str(x[0]))\n",
    "\n",
    "print('\\nWeighted-LS-Positioning')\n",
    "print('x = ' + str(np.round(x_w[0],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output</span>\n",
    "\n",
    "```\n",
    "LS-Positioning\n",
    "x = [3.24]\n",
    "\n",
    "Weighted-LS-Positioning\n",
    "x = [3.01]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.3 Non-linear Least Squares\n",
    "\n",
    "Until now we have assumed that $\\hat{x}$ can be solved as a simple system of equations, i.e. $H$ is a matrix. Nevertheless, typically observation models are non-linear, that is: $z = h(x)$, so the problem now becomes:\n",
    "\n",
    "  $$\n",
    "  \\hat x = \\arg\\min_x ||z-h(x)||^2\n",
    "  $$\n",
    "  \n",
    "  No close-form solutions exists for this new problem, but we can approximate it iteratively:\n",
    "  \n",
    "  $$ \n",
    "  \\textit{(Recall) Taylor expansion: } h(x) = h(x_0+\\delta) = h(x_0) + J_{h_0}\\delta \\\\\n",
    "  ||z-h(x)||^2 \\cong ||\\underbrace{z-h(x_0)}_{\\textit{error vector $e$}}-J_{h_o}\\delta||^2 = ||e-J_{h_0}\\delta||^2 \\leftarrow \\textit{$\\delta$ is unknown, $J_e=-J_{h_0}$}$$\n",
    "  \n",
    "So we can define the equivalent optimization problem:\n",
    "  \n",
    "$$\n",
    "  \\delta = \\arg\\min_\\delta ||e + J_e \\delta||^2 \\rightarrow \\underbrace{\\delta}_{nx1} = -\\underbrace{(J_e^T J_e)^{-1}}_{nxn}\\underbrace{J_e^T}_{nxm} \\underbrace{e}_{mx1} \\textit{ ($\\delta$ that makes the previous squared norm minimum)}\n",
    "  $$\n",
    "  \n",
    "  The weighted form of the $\\delta$ computation results:\n",
    "  \n",
    "  $$\n",
    "  \\delta = (J_e^T Q^{-1} J_e)^{-1}J_e^T Q^{-1} e\n",
    "  $$\n",
    "  \n",
    "Where:\n",
    "  \n",
    "  - $Q$ is the measurement covariance (*weighted measurement*)\n",
    "  - $J_e$ is the negative of the Jacobian of the observation model at $\\hat{x}$, also known as $\\nabla h_{\\hat{x}}$\n",
    "  - $e$ is the error of $z$ against $h(\\hat{x})$ (computed using the map information).\n",
    "  \n",
    "As commented, there is no closed-form solution for the problem, but we can iteratively approximate it using the **Gauss-Newton algorithm**:\n",
    "\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "      &\\hat{x} \\leftarrow (\\dots)  &\\text{(1. Initial guess)} \\\\\n",
    "      &\\delta \\leftarrow (J_e^T Q^{-1} J_e)^{-1} J_e^T  Q^{-1} e  &\\text{(2. Evaluate delta/increment)} \\\\\n",
    "      &\\hat{x} \\leftarrow \\hat{x} - \\delta &\\text{(3. Update estimation)} \\\\\n",
    "      &\\textit{if }\\delta > \\textit{tolerance} \\rightarrow \\textit{goto (1.)} \\\\\n",
    "      &\\textit{else } \\rightarrow \\textit{return }\\hat{x} &\\text{(4. Exit condition)}\\\\\n",
    "  \\end{aligned}\n",
    "  $$\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LS positioning in practice\n",
    "\n",
    "Suppose that a mobile robot equipped with a range sensor aims to localize itself in a map consisting of a number of landmarks by means of Least Squares and Gauss-Newton optimization.\n",
    "\n",
    "For that, **you are provided with** the class `Robot` that implements the behavior of a robot that thinks that is placed at `pose` (that's its initial guess, obtained by composing odometry commands), but that has a real position `true pose`. In addition, the variable `cov` models the uncertainty of its movement, and `var_d` represents the variance (noise) of the range measurements. Take a look at it below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot(object):\n",
    "    \"\"\" Simulate a robot base and positioning.\n",
    "    \n",
    "        Attrs:\n",
    "            pose: Position given by odometry (in this case true_pose affected by noise)\n",
    "            true_pose: True position, selected by the mouse in this demo\n",
    "            cov: Covariance for the odometry sensor. Used to add noise to pose\n",
    "            var_d: Covariance (noise) of each range measurement\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 pose: np.ndarray,\n",
    "                 cov: np.ndarray,\n",
    "                 desv_d: int = 0):\n",
    "        # Pose related        \n",
    "        self.true_pose = pose\n",
    "        self.pose = pose + np.sqrt(cov)@np.random.randn(3, 1)\n",
    "        self.cov = cov\n",
    "        \n",
    "        # Sensor related\n",
    "        self.var_d = desv_d**2\n",
    "    \n",
    "    def plot(self, fig, ax, **kwargs):\n",
    "        DrawRobot(fig, ax, self.pose, color='red', label=\"Pose estimation (Odometry)\", **kwargs)\n",
    "        DrawRobot(fig, ax, self.true_pose, color=\"blue\", label=\"Real pose\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3a: Computing distances from the robot to the landmarks</i></b></span>** \n",
    "\n",
    "**Implement the following function** to simulate how our robot observes the world. In this case, the landmarks in the map act as beacons: the robot can sense how far away they are without any information about angles. The robot uses a range sensor with the following observation model:\n",
    "\n",
    "  $$\n",
    "  z_i=[d_i]=h(m_i,x)=\\left[\\sqrt{(x_i-x)^2+(y_i-y)^2} \\; \\right]+w_i\n",
    "  $$ \n",
    "\n",
    "  where $m_i$ stands for the $i^{th}$ landmark, and $w_i$ is a noise added by the sensor.\n",
    "\n",
    "  Consider two scenarios in the function implementation:\n",
    "  - The measurment is carried out with an ideal sensor, so no noise nor uncertainty exists (`cov_d = 0`).\n",
    "  - The measurement comes from a real sensor affected by a given noise (`cov_d != 0`). We are going to consider that the range sensor is more accurate measuring distances to close landmarks than to far away ones. To implement this, consider that the noise grows with the root of the distance to the landmark, so the resultant uncertainty can be retrieved by: $\\\\[5pt]$\n",
    "$$\n",
    " \\sigma_{\\text{dist}} = \\sigma\\sqrt{z}\\\\[5pt]\n",
    "$$ \n",
    "that is, `np.sqrt(z)*np.sqrt(cov_d)`. Recall that the sensor noise is modeled as a gaussian distribution, so you have to define such distribution and take samples from it  using the [`stats.norm()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) and [`rvs()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.rvs.html) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pose: np.ndarray, m: np.ndarray, cov_d: int = 0) -> np.ndarray:\n",
    "    \"\"\" Get observations for every landmark in the map.\n",
    "\n",
    "    In this case our observations are range only.\n",
    "    If cov_d > 0 then add gaussian noise with var_d covariance\n",
    "\n",
    "    Args:\n",
    "        pose: pose (true or noisy) of the robot taking observation\n",
    "        m: Map containing all landmarks\n",
    "        cov_d: Covariance of the sensor\n",
    "\n",
    "    Returns\n",
    "        z: numpy array containing distances to all obs. It has shape (nLandmars, 1). \n",
    "    \"\"\"\n",
    "    z = None # compute distances to all landmarks\n",
    "\n",
    "    if cov_d > 0:\n",
    "        z += None # add noise if needed\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try your brand new function** with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = np.vstack([2, 2, 0.35])\n",
    "m = np.array([[-5,-15],[20,56],[54,-18]]).T\n",
    "cov_d = 0\n",
    "\n",
    "# Compute distances from the sensor to the landmarks\n",
    "z = distance(pose,m,cov_d)\n",
    "\n",
    "# Now consider a noisy sensor\n",
    "cov_d = 0.5\n",
    "np.random.seed(seed=0)\n",
    "z_with_noise = distance(pose,m,cov_d)\n",
    "\n",
    "# Show the results\n",
    "print('Measurements without noise:' + str(z))\n",
    "print('Measurements with noise:   ' + str(z_with_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output</span>\n",
    "\n",
    "```\n",
    "Measurements without noise:[18.38477631 56.92099788 55.71355311]\n",
    "Measurements with noise:   [23.73319805 59.05577186 60.87928514]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3b: Implementing the algorithm</i></b></span>** \n",
    "\n",
    "Finally, we get to implement the Least Squares algorithm for localization. We ask you to complete the gaps in the following function, which:\n",
    "  - Starts by initializing the Jacobian of the observation function (`Jh`) and takes as initial guess (`xEst`) the position at which the robot thinks it is as given by its odometry (`R1.pose`).\n",
    "  - Then, it enters into a loop until convergence is reached, where:\n",
    "    1. The distances `zEst` to each landmark from the estimated position `xEst`are computed. Recall that the map (landmarks positions) are known (`w_map`).\n",
    "    - The error is computed by substracting to the obsevations provided by the sensor `z` the distances `zEst` computed at the previous point. Then, the residual error is computed as $e_{residual}=\\sqrt{e_x^2+e_y^2}$.\n",
    "    - The Jacobian of the observation model is evaluated at the estimated robot pose (`xEst`). This Jacobian has two columns and as many rows as observations to the landmarks: $\\\\[10pt]$\n",
    "    $$\n",
    "    jH = \n",
    "    \\begin{bmatrix} \n",
    "        \\frac{-1}{d_1}(x_1-x) & \\frac{-1}{d_1}(y_1-y) \\\\\n",
    "        \\frac{-1}{d_2}(x_2-x) & \\frac{-1}{d_2}(y_2-y) \\\\\n",
    "        \\cdots & \\cdots \\\\\n",
    "        \\frac{-1}{d_n}(x_n-x) & \\frac{-1}{d_n}(y_n-y) \\\\ \n",
    "    \\end{bmatrix}\n",
    "    $$    \n",
    "being $xEst=[x,y]$, $[x_i,y_i]$ the position of the $i^{th}$ landmark in the map, and $d$ the distance previously computed from the robot estimated pose $xEst$ to the landmarks. The jacobian of the error `jE`is just `-jH`.\n",
    "    - Computes the increment $\\delta$ (`incr`) and substract it to the estimated pose (`xEst`). *Note: recall that $\\delta = (J_e^T Q^{-1} J_e)^{-1}J_e^T Q^{-1} e$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeastSquaresLocalization(R1: Robot,\n",
    "                             w_map: np.ndarray,\n",
    "                             z: np.ndarray,\n",
    "                             nIterations=10,\n",
    "                             tolerance=0.001,\n",
    "                             delay=0.5) -> np.ndarray:\n",
    "    \"\"\" Pose estimation using Gauss-Newton for least squares optimization\n",
    "    \n",
    "        Args:\n",
    "            R1: Robot which pose we must estimate\n",
    "            w_map: Map of the environment\n",
    "            z: Observation received from sensor\n",
    "            \n",
    "            nIterations: sets the maximum number of iterations (default 10)\n",
    "            tolerance: Minimum error difference needed for stopping the loop (convergence) (default 0.001)\n",
    "            \n",
    "            delay: Wait time used to visualize the different iterations (default 0.5)\n",
    "            \n",
    "        Returns:\n",
    "            xEst: Estimated pose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    # Initialization of useful variables\n",
    "    incr = np.ones((2, 1)) # Delta\n",
    "    jH = np.zeros((w_map.shape[1], 2)) # Jacobian of the observation function of all the landmarks\n",
    "    xEst = R1.pose #Initial estimation is the odometry position (usually noisy)\n",
    "    \n",
    "    # Let's go!\n",
    "    while linalg.norm(incr) > tolerance and iteration < nIterations:\n",
    "        #if plotting:\n",
    "        plt.plot(xEst[0], xEst[1], '+r', markersize=1+math.floor((iteration*15)/nIterations))\n",
    "        # Compute the predicted observation (from xEst) and their respective Jacobians\n",
    "\n",
    "        # 1) TODO: Compute distance to each landmark from xEst (estimated observations w/o noise)\n",
    "        # \n",
    "        zEst = None\n",
    "\n",
    "        # 2) TODO: error = difference between real observations and predticed ones.\n",
    "        e = None\n",
    "        residual = np.sqrt(e.T@e) #residual error = sqrt(x^2+y^2)\n",
    "\n",
    "        # 3) TODO: Compute Jacobians with respect (x,y) (slide 13)\n",
    "        # The jH is evaluated at our current guest (xEst) -> z_p\n",
    "        \n",
    "        jH = None\n",
    "        jE = -jH\n",
    "\n",
    "        # The observation variances Q grow with the root of the distance\n",
    "        Q = np.diag(R1.var_d*np.sqrt(z))\n",
    "\n",
    "        # 4) TODO: Solve the equation --> compute incr\n",
    "        incr = None\n",
    "                    \n",
    "        plt.plot([xEst[0, 0], xEst[0, 0]-incr[0]], [xEst[1, 0], xEst[1, 0]-incr[1]], 'r')\n",
    "        xEst[0:2, 0] -= incr\n",
    "        \n",
    "        print (\"Iteration :\" + str(iteration))\n",
    "        print (\"  delta :   \" + str(incr))\n",
    "        print (\"  residual: \" + str(residual))\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        plt.pause(delay)\n",
    "\n",
    "    plt.plot(xEst[0, 0], xEst[1, 0], '*g', markersize=14, label=\"Final estimation\") #The last estimation is plot in green\n",
    "    \n",
    "    return xEst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell code launches our algorithm, so **we can try it!**. This is done according to the following steps:\n",
    "\n",
    "  1. The map `w_map` is built. In this case, the map consists of a number of landmarks (`nLandmarks`).\n",
    "  2. The program asks the user to set the true position of the robot (`xTrue`) by clicking with the mouse in the map.\n",
    "  3. A new pose is generated from it, `xOdom`, which represents the pose that the robot thinks it is in. This simulates a motion command from an arbitrary pose that ends up with the robot in `xTrue`, but it thinks that it is in `xOdom`.\n",
    "  4. Then the robot takes a (noisy) range measurement to each landmark in the map.\n",
    "  5. Finally, the robot employs a Least Squares definition of the problem and Gauss-Newton to iteratively optimize such a guess (`xOdom`), obtaining a new (and hopefully better) estimation of its pose `xEst`.\n",
    "\n",
    "  **Example**\n",
    "\n",
    "  The figure below shows an example of execution of this code (once completed).\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig5-1-1.png\" width=\"500\" alt=\"\">\n",
    "  <!--figcaption>Fig. 1: </figcaption-->\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(nLandmarks=7, env_size=140):\n",
    "    # MATPLOTLIB\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlim([-90, 90])\n",
    "    plt.ylim([-90, 90])\n",
    "    plt.grid()\n",
    "    plt.ion()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    # VARIABLES\n",
    "    num_landmarks = 7 # number of landmarks in the environment\n",
    "    env_size = 140 # A square environment with x=[-env_size/2,env_size/2] and y=[-env_size/2,env_size/2]\n",
    "       \n",
    "    # MAP CREATION AND VISUALIZATION\n",
    "    w_map = env_size*np.random.rand(2, num_landmarks) - env_size/2 # randomly place the landmarks in the map\n",
    "    ax.plot(w_map[0, :], w_map[1, :], 'o', color='magenta', label=\"Landmarks\")\n",
    "    \n",
    "    # ROBOT POSE AND SENSOR INITIALIZATION \n",
    "    desv_d = 0.5 # standard deviation (noise) of the range measurement\n",
    "    cov = np.diag([25, 30, np.pi*180])**2 # covariance of the motion (odometry)\n",
    "    xStart = np.vstack(plt.ginput(1)).T # get the robot starting point from the user\n",
    "    robot_pose=np.vstack([xStart, 0]) # robot_pose\n",
    "    \n",
    "    R1 = Robot(robot_pose, cov, desv_d)\n",
    "    R1.plot(fig, ax)\n",
    "\n",
    "    # MAIN\n",
    "    z = distance(R1.true_pose, w_map, cov_d=R1.var_d) # take (noisy) measurements to the landmarks\n",
    "    LeastSquaresLocalization(R1, w_map, z) # LS Positioning!\n",
    "    \n",
    "    # PLOTTING RESULTS\n",
    "    plt.legend()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "# RUN    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Having completed this notebook above, you will be able to **answer the following questions**:\n",
    "\n",
    "- What are the dimensions of the error residuals? Does them depend on the number of observations? \n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- Why is Weighted LS obtaining better results than LS?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- Which is the minimum number of landmarks needed for localizing the robot? Why?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- Play with different “qualities” of the range sensor. Could you find a value for its variance so the LS method fails?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- Play also with different values for the odometry uncertainty. What does this affect? \n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
